{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Classification Models for Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample notebook demonstrates how to create a model leveraging the joined dataset leveraging several classification models with **sklearn**.  \n",
    "\n",
    "In this notebook we are leveraging the pandas get_dummies - which for a categorical variable will apply one-hot encoding.  This take a categorical variable and converts to a multiple columns of yes-no 1/0 values  If you set get_dummies option: drop_first=True you can avoid co-linearity in your dataset.\n",
    "\n",
    "Problem is - you would need to ensure that all categorical values are represented in your dataset so when you are inferencing, that column is also in the dataset - so you could add columns, and some folks do, but this take a lot of data engineering.\n",
    "\n",
    "Start with importing required packages for the notebook\n",
    "\n",
    "This notebook will get you going to understand the code required to create the model, but then you need to have a processing pipeline to handle cleaning your data.\n",
    "\n",
    "To handle the dataset transformation, leverage an sklearn pipeline to tranform the data\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the datasets\n",
    "- merge them, get dummies for columns  - super common - but sort of stuipid, makes inferencing tough, but is a quick way to explorer best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 6)\n",
      "(917, 8)\n",
      "(917, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>loc_B</th>\n",
       "      <th>loc_C</th>\n",
       "      <th>loc_D</th>\n",
       "      <th>loc_E</th>\n",
       "      <th>loc_F</th>\n",
       "      <th>loc_G</th>\n",
       "      <th>loc_T</th>\n",
       "      <th>loc_X</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.1500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211.3375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare  survived  pclass   age  sibsp  parch  embarked_Q  embarked_S  \\\n",
       "0    8.0500       0.0     3.0  24.0    0.0    0.0           0           1   \n",
       "1   21.0000       0.0     2.0  43.0    0.0    1.0           0           1   \n",
       "2   24.1500       0.0     3.0  10.0    0.0    2.0           0           1   \n",
       "3   15.5000       0.0     3.0  24.0    0.0    0.0           1           0   \n",
       "4  211.3375       1.0     1.0  43.0    0.0    1.0           0           1   \n",
       "\n",
       "   loc_B  loc_C  loc_D  loc_E  loc_F  loc_G  loc_T  loc_X  sex_male  \n",
       "0      0      0      0      0      0      0      0      1         1  \n",
       "1      0      0      0      0      0      0      0      1         1  \n",
       "2      0      0      0      0      0      0      0      1         0  \n",
       "3      0      0      0      0      0      0      0      1         1  \n",
       "4      1      0      0      0      0      0      0      0         0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./Data/Train1.csv')\n",
    "df2 = pd.read_csv('./Data/Train2.csv')\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "titanic_df = df1.merge(df2, on = 'passenger_id', how = 'inner')\n",
    "\n",
    "titanic_df['survived'] = titanic_df['survived'].fillna(0)\n",
    "titanic_df['loc']= titanic_df['cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'X')\n",
    "titanic_df['age'] = titanic_df.groupby(['pclass'])['age'].apply(lambda x: x.fillna(x.median()))\n",
    "titanic_df = titanic_df.drop(['name', 'ticket', 'home.dest', 'cabin', 'passenger_id'], axis = 1)\n",
    "\n",
    "\n",
    "#get_dummies drop_first will ensure you avoid co-linearity, but makes inferencing more challenging\n",
    "titanic_df = pd.get_dummies(titanic_df, columns = ['embarked', 'loc', 'sex'], drop_first=True)\n",
    "\n",
    "print(titanic_df.shape)\n",
    "\n",
    "FEATURES = list(titanic_df.columns[0:])\n",
    "FEATURES.remove(\"survived\")\n",
    "FEATURES\n",
    "\n",
    "\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the datasets\n",
    "- merge them, use a label encoder to transform data from categorical values into integers suffers from sample problem, inferencing will be a challenge, what goes into a model during training needs to be what goes into the model during inferencing.    \n",
    "- Pretty common - but sort of stupid, makes inferencing tough, but is a quick way to explorer best model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 6)\n",
      "(917, 8)\n",
      "(917, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.1500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211.3375</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fare  embarked  survived  pclass  sex   age  sibsp  parch  loc\n",
       "0    8.0500         2       0.0     3.0    1  24.0    0.0    0.0    8\n",
       "1   21.0000         2       0.0     2.0    1  43.0    0.0    1.0    8\n",
       "2   24.1500         2       0.0     3.0    0  10.0    0.0    2.0    8\n",
       "3   15.5000         1       0.0     3.0    1  24.0    0.0    0.0    8\n",
       "4  211.3375         2       1.0     1.0    0  43.0    0.0    1.0    1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('./Data/Train1.csv')\n",
    "df2 = pd.read_csv('./Data/Train2.csv')\n",
    "print(df1.shape)\n",
    "print(df2.shape)\n",
    "df = df1.merge(df2, on = 'passenger_id', how = 'inner')\n",
    "\n",
    "df['survived'] = df['survived'].fillna(0)\n",
    "df['loc']= df['cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'X')\n",
    "df['age'] = df.groupby(['pclass'])['age'].apply(lambda x: x.fillna(x.median()))\n",
    "df = df.drop(['name', 'ticket', 'home.dest', 'cabin', 'passenger_id'], axis = 1)\n",
    "\n",
    "\n",
    "df_features = list(df.columns)\n",
    "df_features.remove(\"survived\")\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['embarked'] = label_encoder.fit_transform(df['embarked'])\n",
    "df['sex'] = label_encoder.fit_transform(df['sex'])\n",
    "df['loc'] = label_encoder.fit_transform(df['loc'])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on a variety of models.  \n",
    "\n",
    "- Now we can use the dataframe df (label encoding), or the dataframe titanic_df (one-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary for holding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function that leverages sklearn metrics for model evaulation:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_classification(y_test, y_pred):\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred, normalize=True)\n",
    "    num_acc = accuracy_score(y_test, y_pred, normalize=False)\n",
    "\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    \n",
    "    return {'accuracy': acc, \n",
    "            'precision': prec,\n",
    "            'recall':recall, \n",
    "            'accuracy_count':num_acc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic function that takes in a classifer, named label column, named x columns and splits the data trains a model and tests the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(classifier_fn,name_of_y_col, names_of_x_cols, dataset, test_frac=0.2):\n",
    "    \n",
    "    X = dataset[names_of_x_cols]\n",
    "    Y = dataset[name_of_y_col]\n",
    "    #split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_frac, random_state=42)  \n",
    "    #train a model - you pass into the classifier_function so this code can run for many different models\n",
    "    model = classifier_fn(x_train, y_train)   \n",
    "    #predict on the model\n",
    "    y_pred = model.predict(x_test)\n",
    "    #leverage sklearn to get out summary information\n",
    "    test_summary = summarize_classification(y_test, y_pred)   \n",
    "    pred_results = pd.DataFrame({'y_test': y_test,\n",
    "                                 'y_pred': y_pred})\n",
    "    \n",
    "    #pd cross tab will give you a basic confusion matrix of results\n",
    "    model_crosstab = pd.crosstab(pred_results.y_test, pred_results.y_pred)\n",
    "    #print(model_crosstab)\n",
    "    return {'test': test_summary,'confusion_matrix': model_crosstab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results():\n",
    "    for key in result_dict:\n",
    "        print('Classification: ', key)\n",
    "        print('--------------------------------------------')\n",
    "        print('test data')\n",
    "        for score in result_dict[key]['test']:\n",
    "            print(score, result_dict[key]['test'][score])\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model\n",
    "\n",
    "The documentation will help you select the model parameters (hyper parameters for tuning your model)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_fn(x_train, y_train):\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearDiscriminantAnalysis\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html\n",
    "\n",
    "- A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.\n",
    "\n",
    "- The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix.\n",
    "\n",
    "- The fitted model can also be used to reduce the dimensionality of the input by projecting it to the most discriminative directions, using the transform method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_discriminant_fn(x_train, y_train, solver='svd'):\n",
    "    \n",
    "    model = LinearDiscriminantAnalysis(solver=solver)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QuadraticDiscriminantAnalysis\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html\n",
    "    \n",
    "- Quadratic Discriminant Analysis.\n",
    "\n",
    "- A classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes’ rule.\n",
    "\n",
    "- The model fits a Gaussian density to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_discriminant_fn(x_train, y_train):\n",
    "    \n",
    "    model = QuadraticDiscriminantAnalysis()\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "    \n",
    "This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the partial_fit method. For best results using the default learning rate schedule, the data should have zero mean and unit variance.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_fn(x_train, y_train, max_iter=1000, tol=1e-3):\n",
    "    \n",
    "    model = SGDClassifier(max_iter=max_iter, tol=tol)\n",
    "    model.fit(x_train, y_train)\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "\n",
    "Linear Support Vector Classification.\n",
    "\n",
    "Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "* SVC with a linear kernel\n",
    "* dual=False when number of samples > number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svc_fn(x_train, y_train, C=1.0, max_iter=1000, tol=1e-3):\n",
    "    \n",
    "    model = LinearSVC(C=C, max_iter=max_iter, tol=tol, dual=False)\n",
    "    model.fit(x_train, y_train) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RadiusNeighborsClassifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.RadiusNeighborsClassifier.html\n",
    "\n",
    "Classifier implementing a vote among neighbors within a given radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radius_neighbor_fn(x_train, y_train, radius=40.0):\n",
    "\n",
    "    model = RadiusNeighborsClassifier(radius=radius)\n",
    "    model.fit(x_train, y_train) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "**max_depth** = If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples\n",
    "\n",
    "**max_features**  = None -- max_features=n_features, \n",
    "                    auto -- then max_features=sqrt(n_features), \n",
    "                    sqrt -- then max_features=sqrt(n_features), \n",
    "                    log2 -- then max_features=log2(n_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_fn(x_train, y_train, max_depth=None, max_features=None): \n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=max_depth, max_features=max_features)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_fn(x_train,y_train, priors=None):\n",
    "    \n",
    "    model = GaussianNB(priors=priors)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['logistic']                        = build(logistic_fn,              LABEL,FEATURES,titanic_df)\n",
    "result_dict['logistic2']                       = build(logistic_fn,              LABEL,df_features, df)\n",
    "result_dict['linear_discriminant_analysis']    = build(linear_discriminant_fn,   LABEL, FEATURES,titanic_df)\n",
    "result_dict['quadratic_discriminant_analysis'] = build(quadratic_discriminant_fn,LABEL,df_features,df)\n",
    "result_dict['sgd']                             = build(sgd_fn,                   LABEL,FEATURES,titanic_df)\n",
    "result_dict['linear_svc']                      = build(linear_svc_fn,            LABEL,FEATURES,titanic_df)\n",
    "result_dict['radius_neighbors']                = build(radius_neighbor_fn,       LABEL,FEATURES,titanic_df)\n",
    "result_dict['naive_bayes']                     = build(naive_bayes_fn,           LABEL,FEATURES,titanic_df)\n",
    "result_dict['decision_tree']                   = build(decision_tree_fn,         LABEL,FEATURES,titanic_df)\n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
